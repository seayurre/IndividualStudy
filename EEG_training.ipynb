{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./MNE-Python tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnci import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from mne.filter import filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFREQ = 250 #250Hz\n",
    "LOWCUT = 4\n",
    "HIGHCUT = 40\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "t_datas= []\n",
    "t_labels = []\n",
    "for subject in range(1,10):\n",
    "    data, label = get_data_2a(subject, True)\n",
    "    # bandpass filter\n",
    "    data = np.array([filter_data(data=d, sfreq=SFREQ, l_freq=LOWCUT, h_freq=HIGHCUT,\n",
    "                                        verbose=False, fir_design='firwin') for d in data])\n",
    "    # crop the data (imagery part -- 2s to 6s)\n",
    "    data = data[:, :, int(SFREQ * 2):SFREQ * 6]\n",
    "\n",
    "    t_datas.append(data)\n",
    "    t_labels.append(label)\n",
    "\n",
    "#Evaluation Data\n",
    "e_datas=[]\n",
    "e_labels=[]\n",
    "for subject in range(1,10):\n",
    "    data, label = get_data_2a(subject, False)\n",
    "    # bandpass filter\n",
    "    data = np.array([filter_data(data=d, sfreq=SFREQ, l_freq=LOWCUT, h_freq=HIGHCUT,\n",
    "                                        verbose=False, fir_design='firwin') for d in data])\n",
    "    # crop the data (imagery part -- 2s to 6s)\n",
    "    data = data[:, :, int(SFREQ * 2):SFREQ * 6]\n",
    "\n",
    "    e_datas.append(data)\n",
    "    e_labels.append(label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tutorials.pytorch.kr/beginner/basics/buildmodel_tutorial.html  \n",
    "https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html  \n",
    "참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data normalization 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_data(data):\n",
    "        '''\n",
    "\n",
    "        :param data: 3-D EEG data in ndarray (shape: (n_samples, n_channels, n_times))\n",
    "        :return: normalized data in 3-D\n",
    "        '''\n",
    "        data_mean = np.mean(data, axis=(1, 2), keepdims=True)\n",
    "        data_std = np.std(data, axis=(1, 2), keepdims=True)\n",
    "        # divide with data_std with rows that have non-zero std (avoid dividing by zero), std=0 comes from channel_padding\n",
    "        data_std[data_std == 0] = 1\n",
    "        data = (data - data_mean) / data_std\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow ConvNet 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowConvNet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.tempConv = nn.Conv2d(1, 40, (1,25))\n",
    "        self.spaConv = nn.Conv2d(40, 40, (22,1)) \n",
    "        # Batch Normalization\",\n",
    "        #self.batch_norm = nn.BatchNorm2d(40, momentum=0.1, affine=True, eps=1e-5)\n",
    "\n",
    "        self.pool = nn.AvgPool2d((1,75), (1,15))\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Linear Layer for Classification\n",
    "        self.fc = nn.Linear(2440, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if len(x.shape)==3:\n",
    "            x = x.unsqueeze(1)\n",
    "        # Temporal Convolution\n",
    "        x = self.tempConv(x)\n",
    "        x = self.spaConv(x)\n",
    "        #x = self.batch_norm(x)\n",
    "        x = torch.square(x)\n",
    "        # Mean Pooling\n",
    "        x = self.pool(x)\n",
    "        x = torch.log(torch.clamp(x,min=1e-6))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Linear Classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1th subject\n",
      "Epoch: 0   Train accuracy 0.368056   Train loss: 1.576887   Test accuracy is 0.454861   Test loss: 1.159610\n",
      "Epoch: 1   Train accuracy 0.565972   Train loss: 1.088603   Test accuracy is 0.510417   Test loss: 1.073150\n",
      "Epoch: 2   Train accuracy 0.673611   Train loss: 0.821886   Test accuracy is 0.503472   Test loss: 1.145994\n",
      "Epoch: 3   Train accuracy 0.708333   Train loss: 0.666591   Test accuracy is 0.461806   Test loss: 1.629284\n",
      "Epoch: 4   Train accuracy 0.777778   Train loss: 0.545241   Test accuracy is 0.541667   Test loss: 1.278384\n",
      "Epoch: 5   Train accuracy 0.826389   Train loss: 0.521090   Test accuracy is 0.503472   Test loss: 1.867642\n",
      "Epoch: 6   Train accuracy 0.857639   Train loss: 0.378194   Test accuracy is 0.482639   Test loss: 1.816792\n",
      "Epoch: 7   Train accuracy 0.885417   Train loss: 0.313712   Test accuracy is 0.493056   Test loss: 1.683508\n",
      "Epoch: 8   Train accuracy 0.913194   Train loss: 0.221519   Test accuracy is 0.493056   Test loss: 1.607452\n",
      "Epoch: 9   Train accuracy 0.923611   Train loss: 0.191847   Test accuracy is 0.569444   Test loss: 1.482862\n",
      "for 2th subject\n",
      "Epoch: 0   Train accuracy 0.253472   Train loss: 1.911093   Test accuracy is 0.239583   Test loss: 2.051096\n",
      "Epoch: 1   Train accuracy 0.312500   Train loss: 1.632836   Test accuracy is 0.232639   Test loss: 1.736793\n",
      "Epoch: 2   Train accuracy 0.375000   Train loss: 1.517303   Test accuracy is 0.246528   Test loss: 1.786373\n",
      "Epoch: 3   Train accuracy 0.465278   Train loss: 1.376118   Test accuracy is 0.291667   Test loss: 1.795530\n",
      "Epoch: 4   Train accuracy 0.468750   Train loss: 1.300213   Test accuracy is 0.277778   Test loss: 1.959988\n",
      "Epoch: 5   Train accuracy 0.531250   Train loss: 1.096738   Test accuracy is 0.329861   Test loss: 1.777281\n",
      "Epoch: 6   Train accuracy 0.673611   Train loss: 0.863625   Test accuracy is 0.333333   Test loss: 1.937010\n",
      "Epoch: 7   Train accuracy 0.673611   Train loss: 0.793965   Test accuracy is 0.357639   Test loss: 2.030797\n",
      "Epoch: 8   Train accuracy 0.722222   Train loss: 0.744475   Test accuracy is 0.319444   Test loss: 2.347218\n",
      "Epoch: 9   Train accuracy 0.760417   Train loss: 0.607778   Test accuracy is 0.309028   Test loss: 2.720799\n",
      "for 3th subject\n",
      "Epoch: 0   Train accuracy 0.312500   Train loss: 1.825761   Test accuracy is 0.319444   Test loss: 1.742300\n",
      "Epoch: 1   Train accuracy 0.461806   Train loss: 1.320898   Test accuracy is 0.347222   Test loss: 2.035061\n",
      "Epoch: 2   Train accuracy 0.597222   Train loss: 0.997987   Test accuracy is 0.413194   Test loss: 1.825915\n",
      "Epoch: 3   Train accuracy 0.652778   Train loss: 0.842319   Test accuracy is 0.444444   Test loss: 1.868415\n",
      "Epoch: 4   Train accuracy 0.760417   Train loss: 0.631525   Test accuracy is 0.437500   Test loss: 1.886543\n",
      "Epoch: 5   Train accuracy 0.812500   Train loss: 0.533020   Test accuracy is 0.510417   Test loss: 1.489052\n",
      "Epoch: 6   Train accuracy 0.788194   Train loss: 0.548600   Test accuracy is 0.517361   Test loss: 1.767742\n",
      "Epoch: 7   Train accuracy 0.826389   Train loss: 0.396729   Test accuracy is 0.517361   Test loss: 1.506406\n",
      "Epoch: 8   Train accuracy 0.881944   Train loss: 0.313553   Test accuracy is 0.552083   Test loss: 1.507632\n",
      "Epoch: 9   Train accuracy 0.892361   Train loss: 0.269324   Test accuracy is 0.559028   Test loss: 1.597374\n",
      "for 4th subject\n",
      "Epoch: 0   Train accuracy 0.256944   Train loss: 1.841315   Test accuracy is 0.263889   Test loss: 1.921585\n",
      "Epoch: 1   Train accuracy 0.388889   Train loss: 1.463650   Test accuracy is 0.298611   Test loss: 1.886968\n",
      "Epoch: 2   Train accuracy 0.461806   Train loss: 1.237499   Test accuracy is 0.326389   Test loss: 2.153638\n",
      "Epoch: 3   Train accuracy 0.600694   Train loss: 1.013917   Test accuracy is 0.309028   Test loss: 2.431809\n",
      "Epoch: 4   Train accuracy 0.684028   Train loss: 0.819039   Test accuracy is 0.315972   Test loss: 2.346846\n",
      "Epoch: 5   Train accuracy 0.753472   Train loss: 0.651098   Test accuracy is 0.347222   Test loss: 2.289683\n",
      "Epoch: 6   Train accuracy 0.809028   Train loss: 0.537815   Test accuracy is 0.402778   Test loss: 2.042413\n",
      "Epoch: 7   Train accuracy 0.795139   Train loss: 0.541801   Test accuracy is 0.312500   Test loss: 2.372417\n",
      "Epoch: 8   Train accuracy 0.843750   Train loss: 0.417249   Test accuracy is 0.336806   Test loss: 2.336941\n",
      "Epoch: 9   Train accuracy 0.854167   Train loss: 0.410354   Test accuracy is 0.364583   Test loss: 2.317150\n",
      "for 5th subject\n",
      "Epoch: 0   Train accuracy 0.277778   Train loss: 1.939237   Test accuracy is 0.250000   Test loss: 2.293736\n",
      "Epoch: 1   Train accuracy 0.329861   Train loss: 1.480086   Test accuracy is 0.256944   Test loss: 1.996750\n",
      "Epoch: 2   Train accuracy 0.454861   Train loss: 1.255866   Test accuracy is 0.309028   Test loss: 1.953078\n",
      "Epoch: 3   Train accuracy 0.534722   Train loss: 1.150340   Test accuracy is 0.239583   Test loss: 2.419635\n",
      "Epoch: 4   Train accuracy 0.565972   Train loss: 1.065146   Test accuracy is 0.256944   Test loss: 2.832342\n",
      "Epoch: 5   Train accuracy 0.593750   Train loss: 0.978404   Test accuracy is 0.291667   Test loss: 2.529523\n",
      "Epoch: 6   Train accuracy 0.687500   Train loss: 0.804088   Test accuracy is 0.267361   Test loss: 2.944626\n",
      "Epoch: 7   Train accuracy 0.694444   Train loss: 0.738197   Test accuracy is 0.319444   Test loss: 2.455686\n",
      "Epoch: 8   Train accuracy 0.763889   Train loss: 0.641483   Test accuracy is 0.309028   Test loss: 2.278288\n",
      "Epoch: 9   Train accuracy 0.795139   Train loss: 0.540092   Test accuracy is 0.305556   Test loss: 2.518018\n",
      "for 6th subject\n",
      "Epoch: 0   Train accuracy 0.218750   Train loss: 1.894056   Test accuracy is 0.284722   Test loss: 1.677981\n",
      "Epoch: 1   Train accuracy 0.340278   Train loss: 1.509121   Test accuracy is 0.326389   Test loss: 1.718321\n",
      "Epoch: 2   Train accuracy 0.479167   Train loss: 1.342612   Test accuracy is 0.319444   Test loss: 1.844609\n",
      "Epoch: 3   Train accuracy 0.527778   Train loss: 1.219426   Test accuracy is 0.315972   Test loss: 2.012523\n",
      "Epoch: 4   Train accuracy 0.645833   Train loss: 0.998074   Test accuracy is 0.298611   Test loss: 2.294149\n",
      "Epoch: 5   Train accuracy 0.635417   Train loss: 0.888167   Test accuracy is 0.298611   Test loss: 2.590344\n",
      "Epoch: 6   Train accuracy 0.694444   Train loss: 0.844999   Test accuracy is 0.354167   Test loss: 2.564040\n",
      "Epoch: 7   Train accuracy 0.770833   Train loss: 0.620847   Test accuracy is 0.336806   Test loss: 2.460401\n",
      "Epoch: 8   Train accuracy 0.798611   Train loss: 0.525440   Test accuracy is 0.315972   Test loss: 2.869322\n",
      "Epoch: 9   Train accuracy 0.819444   Train loss: 0.508318   Test accuracy is 0.343750   Test loss: 2.508287\n",
      "for 7th subject\n",
      "Epoch: 0   Train accuracy 0.277778   Train loss: 1.881910   Test accuracy is 0.295139   Test loss: 1.781674\n",
      "Epoch: 1   Train accuracy 0.375000   Train loss: 1.514259   Test accuracy is 0.274306   Test loss: 2.233276\n",
      "Epoch: 2   Train accuracy 0.482639   Train loss: 1.238898   Test accuracy is 0.295139   Test loss: 2.011206\n",
      "Epoch: 3   Train accuracy 0.569444   Train loss: 1.044108   Test accuracy is 0.326389   Test loss: 2.037456\n",
      "Epoch: 4   Train accuracy 0.687500   Train loss: 0.776250   Test accuracy is 0.354167   Test loss: 1.842811\n",
      "Epoch: 5   Train accuracy 0.715278   Train loss: 0.721214   Test accuracy is 0.361111   Test loss: 1.938261\n",
      "Epoch: 6   Train accuracy 0.781250   Train loss: 0.564232   Test accuracy is 0.340278   Test loss: 1.906177\n",
      "Epoch: 7   Train accuracy 0.833333   Train loss: 0.467810   Test accuracy is 0.305556   Test loss: 2.461132\n",
      "Epoch: 8   Train accuracy 0.854167   Train loss: 0.359168   Test accuracy is 0.364583   Test loss: 2.025120\n",
      "Epoch: 9   Train accuracy 0.916667   Train loss: 0.270640   Test accuracy is 0.392361   Test loss: 2.253256\n",
      "for 8th subject\n",
      "Epoch: 0   Train accuracy 0.326389   Train loss: 1.752575   Test accuracy is 0.267361   Test loss: 2.193735\n",
      "Epoch: 1   Train accuracy 0.475694   Train loss: 1.284337   Test accuracy is 0.336806   Test loss: 1.771241\n",
      "Epoch: 2   Train accuracy 0.572917   Train loss: 1.006205   Test accuracy is 0.361111   Test loss: 1.741948\n",
      "Epoch: 3   Train accuracy 0.652778   Train loss: 0.832703   Test accuracy is 0.378472   Test loss: 2.206324\n",
      "Epoch: 4   Train accuracy 0.732639   Train loss: 0.664753   Test accuracy is 0.472222   Test loss: 1.611053\n",
      "Epoch: 5   Train accuracy 0.770833   Train loss: 0.606486   Test accuracy is 0.434028   Test loss: 1.882753\n",
      "Epoch: 6   Train accuracy 0.833333   Train loss: 0.484907   Test accuracy is 0.475694   Test loss: 1.912294\n",
      "Epoch: 7   Train accuracy 0.840278   Train loss: 0.408987   Test accuracy is 0.458333   Test loss: 2.059652\n",
      "Epoch: 8   Train accuracy 0.909722   Train loss: 0.241393   Test accuracy is 0.513889   Test loss: 1.738572\n",
      "Epoch: 9   Train accuracy 0.902778   Train loss: 0.272922   Test accuracy is 0.545139   Test loss: 1.746867\n",
      "for 9th subject\n",
      "Epoch: 0   Train accuracy 0.392361   Train loss: 1.624445   Test accuracy is 0.479167   Test loss: 1.307037\n",
      "Epoch: 1   Train accuracy 0.583333   Train loss: 1.054556   Test accuracy is 0.503472   Test loss: 1.297870\n",
      "Epoch: 2   Train accuracy 0.687500   Train loss: 0.745878   Test accuracy is 0.583333   Test loss: 1.294393\n",
      "Epoch: 3   Train accuracy 0.781250   Train loss: 0.543604   Test accuracy is 0.583333   Test loss: 1.284656\n",
      "Epoch: 4   Train accuracy 0.840278   Train loss: 0.396429   Test accuracy is 0.562500   Test loss: 1.428657\n",
      "Epoch: 5   Train accuracy 0.895833   Train loss: 0.261256   Test accuracy is 0.604167   Test loss: 1.350393\n",
      "Epoch: 6   Train accuracy 0.937500   Train loss: 0.195037   Test accuracy is 0.579861   Test loss: 1.536273\n",
      "Epoch: 7   Train accuracy 0.902778   Train loss: 0.237451   Test accuracy is 0.562500   Test loss: 1.667360\n",
      "Epoch: 8   Train accuracy 0.920139   Train loss: 0.205590   Test accuracy is 0.628472   Test loss: 1.482915\n",
      "Epoch: 9   Train accuracy 0.871528   Train loss: 0.334400   Test accuracy is 0.625000   Test loss: 1.827311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for subject in range(9):\n",
    "    print(f\"for {subject + 1}th subject\")\n",
    "    #Network\n",
    "    net = ShallowConvNet()\n",
    "    net.to(device) #using gpu\n",
    "\n",
    "    #prepairing datasets\n",
    "    x_train = _normalize_data(t_datas[subject])\n",
    "    y_train = t_labels[subject]\n",
    "    x_eval = _normalize_data(e_datas[subject])\n",
    "    y_eval = e_labels[subject]\n",
    "\n",
    "    x_eval, y_eval = torch.from_numpy(x_eval).type(torch.FloatTensor), torch.from_numpy(y_eval).type(torch.LongTensor)\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(x_eval, y_eval)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    del test_dataset\n",
    "\n",
    "    #k-fold cross validation은 생략\n",
    "    x_train, y_train = torch.from_numpy(x_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "    del train_dataset\n",
    "\n",
    "    #Define a loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    criterion.to(device)\n",
    "\n",
    "    #####Training#####\n",
    "    for epoch in range(EPOCHS):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for _, (data,labels) in enumerate(train_loader):\n",
    "            ##need to implement train_loader\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = net(data)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            \n",
    "            loss.backward()  # Backward pass (compute gradients)\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            train_loss += loss.item()*labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += float((predicted == labels).cpu().numpy().astype(int).sum())\n",
    "        train_acc = train_correct / train_total\n",
    "        train_loss = train_loss / train_total\n",
    "        \n",
    "        ###Test(Eval)###\n",
    "        test_correct = 0\n",
    "        test_loss=0.0\n",
    "        test_total = 0\n",
    "\n",
    "        for _, (data,labels) in enumerate(test_loader):\n",
    "            ##need to implement train_loader\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()*labels.size(0)\n",
    "\n",
    "            #가장 높은 energy 가지는 class를 정답으로 선택\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += float((predicted == labels).cpu().numpy().astype(int).sum())\n",
    "\n",
    "        test_acc = test_correct / test_total\n",
    "        test_loss = test_loss / test_total\n",
    "\n",
    "        print('Epoch:', epoch,\n",
    "                          '  Train accuracy %.6f' % train_acc,\n",
    "                          '  Train loss: %.6f' % train_loss,\n",
    "                          '  Test accuracy is %.6f' % test_acc,\n",
    "                          '  Test loss: %.6f' % test_loss,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
