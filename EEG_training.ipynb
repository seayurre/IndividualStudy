{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./MNE-Python tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnci import *\n",
    "import torch\n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"C:/Users/NMAIL/Desktop/BNCI dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for MNE EpochsArray data\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, epochs, labels):\n",
    "        \"\"\"\n",
    "        epochs: MNE's EpochsArray object\n",
    "        labels: Corresponding labels for each epoch\n",
    "        \"\"\"\n",
    "        self.epochs = epochs.get_data()  # (n_epochs, n_channels, n_times)\n",
    "        self.labels = labels  # e.g., (n_epochs,)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.epochs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get one sample and its label\n",
    "        sample = self.epochs[idx]  # Shape: (n_channels, n_times)\n",
    "        label = self.labels[idx]   # Corresponding label\n",
    "        \n",
    "        # Convert the sample to PyTorch tensor and reshape to (1, n_times, n_channels)\n",
    "        sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0).permute(0, 2, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "2592 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "epochs_arrays = []\n",
    "classes = []\n",
    "for i in range(1,10):\n",
    "    res_data, res_class = get_data_2a(i, True)\n",
    "    epochs_array = EEG_to_epochs(res_data, res_class,sfreq = 250,)\n",
    "    epochs_arrays.append(epochs_array)\n",
    "    classes.append(res_class)\n",
    "\n",
    "concat_epochs = mne.concatenate_epochs(epochs_arrays)\n",
    "concat_labels = np.concatenate(classes)\n",
    "\n",
    "dataset = EEGDataset(concat_epochs, concat_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tutorials.pytorch.kr/beginner/basics/buildmodel_tutorial.html  \n",
    "https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html  \n",
    "참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowConvNet(\n",
       "  (tempConv): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))\n",
       "  (spaConv): Conv2d(40, 40, kernel_size=(1, 22), stride=(1, 1))\n",
       "  (batch_norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)\n",
       "  (fc): Linear(in_features=4760, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ShallowConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tempConv = nn.Conv2d(1, 40, (25,1))\n",
    "        self.spaConv = nn.Conv2d(40, 40, (1,22)) \n",
    "        # Batch Normalization\n",
    "        self.batch_norm = nn.BatchNorm2d(40)\n",
    "\n",
    "        self.pool = nn.AvgPool2d((75,1), (15,1))\n",
    "\n",
    "        # Linear Layer for Classification\n",
    "        self.fc = nn.Linear(4760, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Temporal Convolution\n",
    "        x = self.tempConv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.spaConv(x)\n",
    "        \n",
    "        # Mean Pooling\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Log Activation\n",
    "        x = torch.log(torch.clamp(x, min=1e-6))  # To avoid log(0)\n",
    "        \n",
    "        # Flatten the output for the dense layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Linear Classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "net = ShallowConvNet()\n",
    "net.to(device) #using gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 119.1721, Accuracy: 25.50%\n",
      "Epoch [2/10], Loss: 119.2299, Accuracy: 25.35%\n",
      "Epoch [3/10], Loss: 119.1642, Accuracy: 25.50%\n",
      "Epoch [4/10], Loss: 119.1997, Accuracy: 25.23%\n",
      "Epoch [5/10], Loss: 119.1657, Accuracy: 25.46%\n",
      "Epoch [6/10], Loss: 119.1736, Accuracy: 25.04%\n",
      "Epoch [7/10], Loss: 119.1990, Accuracy: 25.31%\n",
      "Epoch [8/10], Loss: 119.1279, Accuracy: 25.27%\n",
      "Epoch [9/10], Loss: 119.1015, Accuracy: 25.42%\n",
      "Epoch [10/10], Loss: 119.1087, Accuracy: 25.46%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        outputs = net(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        \n",
    "        loss.backward()  # Backward pass (compute gradients)\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(288, 22, 1875)\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "2592 matching events found\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "evaluation_epochs_arrays = []\n",
    "evaluation_classes = []\n",
    "for i in range(1,10):\n",
    "    res_data, res_class = get_data_2a(i, False)\n",
    "    epochs_array = EEG_to_epochs(res_data, res_class,sfreq = 250,)\n",
    "    evaluation_epochs_arrays.append(epochs_array)\n",
    "    evaluation_classes.append(res_class)\n",
    "\n",
    "ev_concat_epochs = mne.concatenate_epochs(evaluation_epochs_arrays)\n",
    "ev_concat_labels = np.concatenate(evaluation_classes)\n",
    "\n",
    "ev_dataset = EEGDataset(ev_concat_epochs, ev_concat_labels)\n",
    "dataloader = DataLoader(ev_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 24 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
